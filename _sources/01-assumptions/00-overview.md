# Assumptions 
---
_Things that turn "natural language" into something worth processing_

Table of Contents
1. Rules-based before Data-driven
   - Tokenization: Rules for Matching & Splitting
   - Ontology: Rules for Relationship & Meaning
2. Data drives the need for context
   - Local Sequences and Probabilities
   - Global Frequencies and Context
   - Perfectly Balanced? 
   


